{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc08e11f-70cf-4f62-af15-f86654875f1f",
   "metadata": {},
   "source": [
    "# More testing practice...\n",
    "<img src='../images/xebia-logo.png' width='300px' align='right' style=\"padding: 15px\">\n",
    "\n",
    "### ... and high-quality-code-writing practice!\n",
    "\n",
    "Your goal for this section of the training will be to refactor some code produced by a Data Scientist that implements a ML application for the animal shelter usecase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cfc279-8f30-415c-a88f-b2fb77d65f46",
   "metadata": {},
   "source": [
    "A good design principle is that ***good* functions are *testable* functions**. So try to break down the code at the end of the notebook into the smallest units that you think makes sense testing.\n",
    "\n",
    "Once the code is refactored, you should be able to call the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ce0ef6-1528-4a45-8c22-43c55f6c9c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from animal_shelter.model.train import train\n",
    "from animal_shelter.model.predict import predict\n",
    "\n",
    "train(\"../data/train.csv\", \"../output/model.pkl\")\n",
    "predict(\"../data/test.csv\", \"../output/model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd9355f-d70c-4439-848e-386a46dea895",
   "metadata": {},
   "source": [
    "1. Create a subpackage called `model` within `animal_shelter`.\n",
    "2. Create two modules called `train.py` and `predict.py` within that subpackage.\n",
    "3. Copy-paste the code from bellow into the respective modules, and make sure that all imports are correct.\n",
    "4. Refactor the code into smaller functions, and write unit tests for their essential behaviour.\n",
    "    - Think about which individual steps/functions ***make sense testing***, and which do not require testing (and why).\n",
    "    - Think about which parameter types your functions should accept, and add type hints.\n",
    "    - Here are some pointers:\n",
    "        - You probably want a function called `train` that accepts a `Path` (from `pathlib`) to the training data and another `Path` to a location where to save a fitted model (e.g. `output/model.pkl`).\n",
    "        - You probably want to abstract away the process of building the `Pipeline` into a separate function so that you can test that it's constructed properly.\n",
    "        - You probably also want a function called `predict` that accepts a `Path` to the data and a `Path` to the model used to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a8b80f-6fbd-4a8c-94c9-7ab108bddfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from animal_shelter.data import load_data\n",
    "from animal_shelter.features import add_features\n",
    "\n",
    "raw_data = load_data(\"../data/train.csv\")\n",
    "with_features = add_features(raw_data)\n",
    "cat_features = [                                  \n",
    "    \"animal_type\",                                        \n",
    "    \"is_dog\",                                             \n",
    "    \"has_name\",                                           \n",
    "    \"sex\",                                                \n",
    "    \"hair_type\",                                          \n",
    "]                                                         \n",
    "num_features = [\"days_upon_outcome\"]                  \n",
    "\n",
    "num_transformer = Pipeline(                                                \n",
    "    steps=[(\"imputer\", SimpleImputer()), (\"scaler\", StandardScaler())]     \n",
    ")                                                                          \n",
    "cat_transformer = Pipeline(steps=[(\"onehot\", OneHotEncoder(drop=\"first\"))])\n",
    "transformer = ColumnTransformer(                                           \n",
    "    (                                                                      \n",
    "        (\"numeric\", num_transformer, num_features),                        \n",
    "        (\"categorical\", cat_transformer, cat_features),                    \n",
    "    )                                                                      \n",
    ")\n",
    "\n",
    "clf_model = Pipeline(                                                      \n",
    "    [(\"transformer\", transformer), (\"model\", RandomForestClassifier())]    \n",
    ")\n",
    "                                                          \n",
    "X = with_features[cat_features + num_features]\n",
    "y = with_features[\"outcome_type\"] \n",
    "\n",
    "clf_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60bc235-74b2-4d46-a024-ab40dc9c5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data(\"../data/test.csv\")\n",
    "with_features = add_features(test_data)\n",
    "X_test = with_features[cat_features + num_features]\n",
    "clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb677118",
   "metadata": {},
   "source": [
    "Don't know how to start? Here are some helpers:\n",
    "\n",
    "<details>\n",
    "    \n",
    "  <summary><span style=\"color:yellow\">Click here for package advise</span></summary>\n",
    "  \n",
    "First, expand your package to add the `model` subpackage and modules. The structure should end up something like this:\n",
    "\n",
    "```plain\n",
    "├── src/​\n",
    "│  └─ animal_shelter/​\n",
    "│     ├── __init__.py​\n",
    "│     ├── data.py​\n",
    "│     ├── features.py​\n",
    "│     └─ model/\n",
    "│        ├── __init__.py​\n",
    "│        ├── train.py​\n",
    "│        └── predict.py​\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    \n",
    "  <summary><span style=\"color:yellow\">Click here for refactoring advise</span></summary>\n",
    "  \n",
    "Second, copy-paste the first code block above into `train.py`, and refactor it into smaller functions. Your should end up with something like this:\n",
    "\n",
    "```python\n",
    "import (...)\n",
    "\n",
    "def train(...):\n",
    "    \"\"\"\n",
    "    Trains model given a `data_path` and save it to the `model_path`.\n",
    "    \"\"\"\n",
    "    # TODO: Load data, build pipeline(/\"model\"), fit model, save model\n",
    "\n",
    "def _build_pipeline(...):\n",
    "    \"\"\"\n",
    "    Builds the model sklearn model pipeline.\n",
    "    \"\"\"\n",
    "    # TODO: Build a sklearn pipeline\n",
    "\n",
    "def _fit_model(...):\n",
    "    \"\"\"\n",
    "    Trains the model pipeline.\n",
    "    \"\"\"\n",
    "    # TODO: Fit the sklearn pipeline\n",
    "\n",
    "def _save_model(...):\n",
    "    \"\"\"\n",
    "    Saves the trained model.\n",
    "    \"\"\"\n",
    "    # TODO: Save model (e.g., use joblib.dump(model, path))\n",
    "```\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
